import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.regression.LinearRegression

import org.apache.log4j._
Logger.getLogger("org").setLevel(Level.ERROR)

val spark = SparkSession.builder().getOrCreate()
val data = spark.read.option("header", "true").option("inferSchema", "true").csv("kc_house_data.csv")

data.printSchema()

for (row <- data.head(10)){
  println(row)
}
//
// // (label, feature) (một array và mỗi cái một cột)

import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors

val df = (data.select(data("Price").as("label"), $"bedrooms"
, $"bathrooms",
$"sqft_living", $"sqft_lot", $"floors", $"waterfront", $"view", $"condition", $"grade", $"sqft_above", $"sqft_basement", $"yr_built", $"yr_renovated", $"zipcode", $"lat", $"long", $"sqft_living15", $"sqft_lot15"))



//VectorAssembler: convert array into vector
//input columns
val assembler = (new VectorAssembler().setInputCols(Array("bedrooms", "bathrooms",
"sqft_living", "sqft_lot", "floors", "waterfront", "view", "condition", "grade", "sqft_above", "sqft_basement", "yr_built", "yr_renovated", "zipcode", "lat", "long", "sqft_living15", "sqft_lot15")).setOutputCol("features"))


val output = assembler.transform(df).select($"label", $"features")

val lr = new LinearRegression()

val lrModel = lr.fit(output)

val trainingSummary = lrModel.summary

trainingSummary.residuals.show()
